

# ğŸ“„ **README â€” Export du Meilleur ModÃ¨le (Machine Learning)**

## ğŸ¯ Objectif
AprÃ¨s avoir entraÃ®nÃ© plusieurs modÃ¨les de prÃ©diction du risque cardiovasculaire (RandomForest, Logistic Regression), nous avons sÃ©lectionnÃ© **le meilleur modÃ¨le** selon des mÃ©triques adaptÃ©es au contexte mÃ©dical (Recall, F1-score, ROC AUC).
Lâ€™objectif de cette Ã©tape est dâ€™exporter ce modÃ¨le afin quâ€™il puisse Ãªtre utilisÃ© dans lâ€™API de prÃ©diction.

---
## ğŸ§  Pourquoi exporter le modÃ¨le ?
Le notebook dâ€™entraÃ®nement sert uniquement Ã  :
- charger les donnÃ©es
- prÃ©parer les features
- entraÃ®ner plusieurs modÃ¨les
- comparer leurs performances

Mais lâ€™API (FastAPI) a besoin dâ€™un **fichier modÃ¨le** pour faire des prÃ©dictions sur de nouvelles donnÃ©es.
Ce fichier doit contenir :
- le modÃ¨le entraÃ®nÃ©
- le scaler utilisÃ© pour normaliser les donnÃ©es
- la liste des features dans le bon ordre
Câ€™est ce que nous appelons un **model package**.
---

## ğŸ† SÃ©lection du meilleur modÃ¨le
AprÃ¨s comparaison des performances :

- **RandomForest (balanced)** â†’ accuracy Ã©levÃ©e mais recall trÃ¨s faible
- **Logistic Regression (balanced)** â†’ recall Ã©levÃ©, F1-score meilleur, ROC AUC supÃ©rieur

Dans un contexte mÃ©dical, la prioritÃ© est de **dÃ©tecter les patients Ã  risque**.
Nous avons donc choisi :

### âœ”ï¸ **ModÃ¨le final : Logistic Regression (class_weight="balanced")**

---

## ğŸ“¦ Construction du â€œmodel_packageâ€
Pour que lâ€™API puisse utiliser le modÃ¨le, nous avons regroupÃ© dans un dictionnaire Python :

- `model` â†’ le modÃ¨le entraÃ®nÃ©
- `scaler` â†’ lâ€™objet StandardScaler utilisÃ© pour normaliser les donnÃ©es
- `features` â†’ la liste des colonnes utilisÃ©es pour lâ€™entraÃ®nement

Ce package garantit que lâ€™API reproduira exactement les mÃªmes transformations que lors de lâ€™entraÃ®nement.

---

## ğŸ’¾ Export du modÃ¨le au format `.pkl`

Voici le code utilisÃ© pour exporter le modÃ¨le :

```python
# ============================
# 14. EXPORT DU MEILLEUR MODÃˆLE
# ============================

import pickle

# SÃ©lection du meilleur modÃ¨le selon les mÃ©triques
best_model = log_reg

# Construction du package contenant tout ce dont l'API a besoin
model_package = {
    "model": best_model,                     # modÃ¨le final entraÃ®nÃ©
    "scaler": scaler,                        # scaler utilisÃ© pour normaliser les donnÃ©es
    "features": X_scaled.columns.tolist()    # liste des colonnes dans le bon ordre
}

# Sauvegarde du package dans un fichier pickle
with open("cardio_model.pkl", "wb") as f:
    pickle.dump(model_package, f)

print("ModÃ¨le sauvegardÃ© dans cardio_model.pkl")
```

---

## ğŸ“ OÃ¹ placer le fichier exportÃ© ?
Pour respecter une architecture propre :

```
model_training/
    training.ipynb

model_api/
    cardio_model.pkl   â† fichier exportÃ© ici
    model.py
    requirements.txt
```

- Le notebook reste dans `model_training/`
- Le modÃ¨le `.pkl` est placÃ© dans `model_api/` car câ€™est lÃ  que lâ€™API le chargera

---

## ğŸš€ Ã‰tape suivante
Lâ€™API FastAPI pourra maintenant :

1. charger `cardio_model.pkl`
2. appliquer le scaler
3. prÃ©parer les donnÃ©es dans le bon ordre
4. exÃ©cuter `model.predict()`
5. renvoyer une prÃ©diction fiable

